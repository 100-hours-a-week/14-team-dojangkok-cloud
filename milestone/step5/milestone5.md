# Milestone5 : 수동 롤백 프로세스 정립 및 장애 알림 시스템 구축

## 1. 수동 롤백 프로세스

현재 도장콕 서비스는 자동화된 롤백 시스템 대신 **담당자에 의한 수동 롤백** 방식을 채택하고 있습니다. 이는 MVP 개발 단계의 특성과 인프라 환경을 고려한 전략적 의사결정으로, 그 구체적인 이유는 다음과 같습니다.

### 1) MVP 단계의 선택과 집중
초기 개발 단계에서는 한정된 리소스를 가장 효율적인 곳에 투입해야 합니다. 복잡한 자동 롤백 파이프라인을 구축하는 데 드는 엔지니어링 비용을 **기본적인 배포 환경 안정화**, **모니터링 환경 구축**, **데이터베이스 백업 전략 수립**에 투자하는 것이 서비스 안정성에 더 큰 기여를 한다고 판단했습니다.

### 2) 자동화의 잠재적 리스크 관리
명확한 롤백 정책이 정립되지 않은 상태에서의 섣부른 자동화는 오히려 서비스 가용성을 해칠 수 있다고 판단했습니다. 단순한 네트워크 지연이나 일시적인 외부 API 오류 등 애플리케이션 로직과 무관한 이슈로 인해 Health Check가 실패할 수 있습니다. 이때 자동 롤백이 트리거되면, 실제로는 정상 배포된 기능까지 불필요하게 취소되는 부작용이 발생할 수 있습니다. 장애 발생 시 **담당자가 로그와 메트릭을 기반으로 원인을 파악**한 후, 롤백 여부를 결정하는 방식을 유지하여 불필요한 배포 취소를 방지합니다.

### 3) 인프라 구조의 단순함과 CI/CD 활용성
현재 도장콕의 인프라는 단일 EC2 인스턴스와 빅뱅 배포 방식을 따르고 있어 구조가 매우 직관적입니다. 복잡한 마이크로서비스나 분산 환경이 아니므로, 문제 발생 시 이전 버전으로 되돌리는 과정이 단순합니다. 또한 별도의 복잡한 롤백 스크립트 없이도 기존 성공했던 **Workflow를 재실행**하는 것만으로 신속하고 안정적인 롤백이 가능합니다.

따라서 현 단계에서는 과도한 자동화 시스템 구축보다는, **담당자의 판단에 기반한 확실한 수동 롤백** 처리가 MVP 모델의 운영 효율성과 안정성에 더 부합한다고 판단하였습니다.

## 2. 수동 롤백 프로세스 절차

현재 도장콕은 별도의 롤백 스크립트나 빌드 파일 서버를 운영하지 않고, **Github Actions의 Workflow 재실행(Re-run)** 기능을 활용하여 효율적인 수동 롤백을 수행하고 있습니다. 구체적인 절차는 다음과 같습니다.

### 1) 롤백 대상 Workflow 식별
![수동롤백 1단계](https://raw.githubusercontent.com/100-hours-a-week/14-team-dojangkok-cloud/refs/heads/main/milestone/step5/images/manual_rollback_1.png)
- 도장콕은 **Main Branch Merge** 이벤트 발생 시 배포가 수행됩니다. 현재 배포된 버전에 장애가 감지되어 롤백이 결정된 상황을 가정합니다.
- Github Actions 탭의 Workflow 목록에서, **가장 최근에 성공적으로 배포되었던(Stable) 시점**의 Workflow를 식별하여 클릭합니다.

### 2) 재실행 범위 선정 (Artifacts 활용)
![수동롤백 2단계](https://raw.githubusercontent.com/100-hours-a-week/14-team-dojangkok-cloud/refs/heads/main/milestone/step5/images/manual_rollback_2.png)
- 도장콕은 빌드 산출물을 **Github Artifacts**로 관리하고 있어, 별도의 형상 관리 없이도 과거 빌드 파일에 접근할 수 있습니다. (Retention: 7일)
- **Artifacts 유효 기간(7일) 이내**: 이미 빌드된 파일이 존재하므로, 전체 과정을 수행할 필요 없이 **Deploy Job만 선택적으로 재실행**하여 신속하게 롤백합니다.
- **Artifacts 유효 기간 경과**: 빌드 파일이 만료되었으므로, **전체 Workflow를 재실행(Re-run all jobs)**하여 빌드부터 배포까지 새로 수행합니다.

### 3) Workflow 재실행 및 롤백 수행
![수동롤백 3단계](https://raw.githubusercontent.com/100-hours-a-week/14-team-dojangkok-cloud/refs/heads/main/milestone/step5/images/manual_rollback_3.png)
- **Re-run jobs** 버튼을 클릭하여 롤백을 시작합니다.
- 실행이 완료되면 해당 버전의 애플리케이션이 서버에 적용되어 서비스가 정상화됩니다.

## 3. 모니터링 시스템

현재 도장콕 서비스는 AWS(FE/BE)와 GCP(AI Server/Model) 인프라가 모두 **단일 인스턴스**로 구성된 MVP 모델입니다. 이러한 단일 인스턴스 환경에서는 자원 포화나 장애 발생이 서비스 전체 중단으로 이어질 수 있어, 트래픽 유입 패턴과 시스템 상태에 대한 철저한 모니터링이 필수적입니다.

도장콕은 현재 인프라 수준의 모니터링, 애플리케이션/AI 모델 수준의 모니터링을 모두 준비하고 있으며, 현재는 인프라 수준과 일부 애플리케이션에 대한 모니터링을 구축해둔 상태입니다.

현재 모니터링 시스템의 주요 특징은 다음과 같습니다.

1. **PLG Stack**: Prometheus, Loki, Grafana 로 모니터링 시스템이 구축되어 있습니다.
2. **별도 인스턴스**: 애플리케이션 서빙 목적의 인스턴스와 분리되어 있습니다.
3. **AWS 인프라**: AWS/GCP 멀티클라우드 환경에서 AWS에 모니터링 서비스 인스턴스를 두었습니다.

### 1. PLG Stack (Prometheus, Loki, Grafana)
도장콕은 효율적인 모니터링을 위해 업계 표준인 **PLG Stack**을 도입했습니다. 각 구성 요소의 역할은 다음과 같습니다.

| 기술 | 역할 | 용도 |
| :--- | :--- | :--- |
| **Prometheus** | Metric | 인프라 및 애플리케이션의 시계열 데이터(CPU, 메모리, 요청 수 등) 수집/저장 |
| **Loki** | Log | 분산된 서버의 시스템 로그 및 애플리케이션 로그 통합 관리 |
| **Grafana** | Visualization | 수집된 메트릭과 로그를 단일 대시보드에서 시각화 및 알림(Alert) 설정 |

#### 도입 이유: 멀티클라우드 환경의 통합 관제
현재 도장콕은 **AWS**와 **GCP**를 함께 사용하는 멀티클라우드 환경입니다. 각 클라우드 제공자가 제공하는 Native 도구(AWS CloudWatch, GCP Cloud Monitoring)를 사용할 경우, 다음과 같은 비효율이 발생합니다.

- **파편화된 모니터링**: 클라우드별로 별도의 콘솔을 확인해야 하므로 전체 시스템 상황을 한눈에 파악하기 어렵습니다.
- **운영 복잡도 증가**: 각 플랫폼마다 다른 설정 방식과 알림 정책을 관리해야 하는 오버헤드가 발생합니다.

반면, **PLG Stack**을 구축함으로써 이종 클라우드 환경의 메트릭과 로그를 **하나의 Grafana 대시보드로 중앙 집중화**하여 운영 효율성을 극대화했습니다. 또한, 커스텀 대시보드 구성의 자유도가 높아 운영자가 원하는 지표를 직관적으로 시각화하기에 유리합니다.

현재는 컨테이너화가 적용되지 않은 인프라 환경이므로, PLG Stack 환경을 구축하기 위해 필요한 모든 서비스들을 인스턴스에 **네이티브로 직접 설치**하였습니다.

### 2. 인스턴스 분리 및 배치 전략
도장콕의 모니터링 시스템은 **애플리케이션 서버와 완전히 분리된 별도의 AWS EC2 인스턴스**에 구축되었습니다. 이러한 아키텍처를 선택한 구체적인 이유는 다음과 같습니다.

#### 1) 리소스 격리 (Resource Isolation)
모니터링 시스템(특히 Prometheus와 Loki)은 수집된 데이터를 메모리에 적재하거나 디스크에 쓰는 I/O 작업이 빈번하며, 대시보드 조회 시 무거운 쿼리가 실행될 수 있습니다.
- **안정성 확보**: 만약 애플리케이션 서버와 함께 구동할 경우, 모니터링 부하로 인해 정작 중요한 서비스 성능이 저하되는 문제가 발생할 수 있습니다. 이를 방지하기 위해 물리적으로 컴퓨팅 자원을 분리하여 서비스 안정성을 보장했습니다.

#### 2) 통신 비용 최적화 (Cost Optimization)
도장콕은 AWS(FE/BE)와 GCP(AI)를 모두 사용하는 멀티클라우드 환경이지만, 모니터링 서버는 **AWS**에 배치했습니다.
- **데이터 발생량**: 사용자 트래픽의 대부분을 처리하는 FE/BE 애플리케이션(AWS)이 AI 모델(GCP)에 비해 압도적으로 많은 로그와 메트릭을 생성합니다.
- **비용 절감**: 모니터링 서버를 데이터 발생량이 많은 AWS 쪽에 배치함으로써, 클라우드 간(AWS <-> GCP) 데이터 전송 시 발생하는 **Egress Network 비용(통신 비용)을 최소화**하였습니다.

## 4. 경보 시스템

현재는 시스템 안정성에 가장 직접적인 영향을 미치는 **인프라 레벨의 리소스 지표**를 중심으로 알림을 구성하였으며, 클라우드 환경(AWS, GCP)별 특성에 맞춰 임계치를 최적화했습니다.

![경보 시스템](https://raw.githubusercontent.com/100-hours-a-week/14-team-dojangkok-cloud/refs/heads/main/milestone/step5/images/alerts.png)

AWS(Web/DB)와 GCP(AI) 인프라에 적용된 구체적인 임계치 설정 기준과 그 근거는 다음과 같습니다.

| 리소스 | 임계치 | 설정 근거 |
| :--- | :--- | :--- |
| **CPU** | **80%** | 단일 인스턴스에서 CPU 포화는 서비스 지연뿐만 아니라 운영자의 SSH 접속 처리조차 지연시킬 수 있습니다. 장애 대응을 위한 최소한의 시스템 리소스와 시간을 확보하기 위해 80%를 한계선으로 설정했습니다. |
| **RAM** | **80%** | 리눅스 커널은 메모리 부족 시 중요 프로세스를 강제 종료(Kill)합니다. DB와 앱이 함께 실행되는 환경에서 프로세스 생존을 보장하기 위한 안전장치, OS의 파일 시스템 캐시 효율성을 유지하기 위한 마지노선으로서 80%를 임계치로 설정했습니다. |
| **DISK** | **85%** | 디스크가 100%가 되면 DB 트랜잭션 기록 불가로 서비스가 즉시 멈춥니다. 로그 로테이션이나 볼륨 증설 작업을 수행할 수 있는 물리적인 시간을 확보하기 위해 15%의 여유를 두었습니다. |
| **VRAM** | **95%** | 현재 **vLLM이 GPU 메모리의 85%를 사전 점유(Pre-allocation)**하고 있습니다. 95% 도달은 KV Cache가 한계에 다다랐거나 의도치 않은 메모리 누수가 발생했다는 신호로, 인퍼런스 요청 실패(OOM) 직전의 위험 상태를 의미합니다. |